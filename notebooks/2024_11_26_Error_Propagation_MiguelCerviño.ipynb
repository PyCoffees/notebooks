{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad33bf6-8c78-471e-8185-248a60e84ebd",
   "metadata": {},
   "source": [
    "# Uncertainty: description vs. propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab6260-a5ce-4d70-84ef-928f75fda1ed",
   "metadata": {},
   "source": [
    "`Miguel Cerviño 27 Nov 2024`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ea7f4-69b3-4f64-9b57-83718c716142",
   "metadata": {},
   "source": [
    "References (ask me if you do not find any of them):\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.iso.org/sites/JCGM/GUM-introduction.htm\"><i>Guide to the expresion of uncertainty in measurements, GUM</i></a> (form the International Standarization Organization, ISO)<br>\n",
    "            In particular <a href=\"https://www.iso.org/sites/JCGM/GUM/JCGM100/C045315e-html/C045315e.html?csnumber=50461\">Sect 7: Reporting uncertainty</a></li>\n",
    "        <li><i>Kendall's Advanced Theory of Statistics</i> (Vol 1 Cap.1,2,3)) It is in CAB library</li>\n",
    "        <li>D'Agostini (2013) <i>Bayesian reasoning in data analisys . A critical introduction</i> World Scientific Publishing 2003 (<a href=\"https://www.roma1.infn.it/~dagos/WSPC/index.html\">Table of contents</a>)</li>\n",
    "        <li> <font color=\"green\" >&#128073; </font> D'Agostini &amp; Raso (2000) <i>Uncertainties due to imperfect knowledge of systematic effects</i> (<a href=\"http://arxiv.org/abs/hep-ex/0002056v1\">http://arxiv.org/abs/hep-ex/0002056v1</a>)</li>\n",
    "        <li>Maíz-Apellániz &amp; Úbeda Ap.J. 2005, 629, 873, <a href=\"https://ui.adsabs.harvard.edu/abs/2005ApJ...629..873M/abstract\"><i>Numerical Biases on Initial Mass Function Determinations Created by Binning</i></a></li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da277397-ad10-4519-8970-ca2da9d94b57",
   "metadata": {},
   "source": [
    "## 0. Preliminaries: Some useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133bc71-5fd6-4419-99a4-a9b28d423fa7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32289084-1913-4577-b2eb-60630396b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from numpy import empty\n",
    "from scipy.special import erfinv, erf\n",
    "#from scipy.stats import triang\n",
    "#Estos dos no se si se usan!!!\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from matplotlib.ticker import AutoMinorLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6038bac1-7868-4db0-b716-c889558efb1c",
   "metadata": {},
   "source": [
    "### Analisys functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de334bf-216b-40e7-859e-3c3bea6d75fc",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Index function (<font color=\"#8888aa\"><i>is_odd</i></font>)</li>\n",
    "    <li>Plotting histogram functions (<font color=\"#8888aa\"><i>plot_histloglin, plot_histloglog, plot_histlinlog</i></font>)</li>\n",
    "    <li>&#128073;  Analisys functions: mean and sigma, median and quartil, mode and CL, and PDF plotting functions (<font color=\"#8888aa\"><i>PlotPDF(x, Qmedian, Qcl)</i></font>)</li>\n",
    "    <li> Definitions (<font color=\"#8888aa\"><i>&lt;function&gt;FUN</i></font>), Montecarlo samplig (<font color=\"#8888aa\"><i>&lt;function&gt;PDF</i></font>), Monments and Quantiles (<font color=\"#8888aa\"><i>&lt;function&gt;MomentsAndQantiles</i></font>) and histogram and function ploting (<font color=\"#8888aa\"><i>&lt;function&gt;PLOT</i></font>) of some asymmetric PDFs\n",
    "        <ol>\n",
    "        <li>PowerLaw PDF and analitical moments and quartiles (<font color=\"#8888aa\"><i>powerlaw</i></font>)</li>\n",
    "        <li>Triangular PDF and analitical moments and quartiles (<font color=\"#8888aa\"><i>tirangular</i></font>)</li>\n",
    "        <li>Splitnormal PDF and analitical moments and quartiles (<font color=\"#8888aa\"><i>splitnormal</i></font>)</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc5a13-ea3e-4270-aa49-23660eb21b3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Code with Fucntions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ecf65e-117b-4e05-9ebb-69d26d32ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_odd(num):\n",
    "    return num & 0x1\n",
    "\n",
    "# Plot an histogram in log-linear, \n",
    "#taken from https://stackoverflow.com/questions/47850202/plotting-a-histogram-on-a-log-scale-with-matplotlib/54529366#54529366\n",
    "def plot_histloglin(x, bins):\n",
    "  hist, bins = np.histogram(x, bins=bins)\n",
    "  logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
    "  plt.hist(x, bins=logbins,density=True)\n",
    "  plt.xscale('log')\n",
    "\n",
    "# Plot an histogram in log-log, \n",
    "def plot_histloglog(x, bins):\n",
    "  hist, bins = np.histogram(x, bins=bins)\n",
    "  logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
    "  plt.hist(x, bins=logbins,density=True)\n",
    "  plt.xscale('log')\n",
    "  plt.yscale('log')\n",
    "\n",
    "# Plot an histogram in log-log, \n",
    "def plot_histlinlog(x, bins):\n",
    "  hist, bins = np.histogram(x, bins=bins)\n",
    "  plt.hist(x, bins=bins,density=True)\n",
    "  plt.yscale('log')\n",
    "\n",
    "# example plot_histloglin(np.random.rand(200), 10)\n",
    "\n",
    "#Plot histogram, obtain, mean, varinace, median, 90%Q, mode, 90%CL\n",
    "def plot_PDF(x, Qmedian, Qcl, Nbins = 20, xlog=False, ylog=False, title=' ',xsize=12,ysize=5):\n",
    "    xdata = np.array(x)\n",
    "\n",
    "    # mean, median, Qmedian\n",
    "    # mean\n",
    "    xmean = np.mean(xdata)\n",
    "    xstd = np.std(xdata)\n",
    "\n",
    "    # Median and Quatil\n",
    "    nQlow = 0.5 - (Qmedian / 2)\n",
    "    nQmedian = 0.5\n",
    "    nQup = 0.5 + ( Qmedian / 2)\n",
    "    \n",
    "    xQlow = np.quantile(xdata, nQlow)\n",
    "    xmedian = np.quantile(xdata, nQmedian)\n",
    "    xQup = np.quantile(xdata, nQup)\n",
    "\n",
    "    # Mode\n",
    "    # 1) sort array\n",
    "    Npt = int(len(xdata))\n",
    "    xsorted = np.take_along_axis(xdata,np.argsort(xdata),axis=0)\n",
    "\n",
    "    # Mode an Intervals (assuming 20 bins and Npt is multiple by 20)\n",
    "    Npt_bin = int(Npt / Nbins)\n",
    "\n",
    "    Histo_array = []\n",
    "    bins = []\n",
    "    bins.append(xsorted[0])\n",
    "    irun = 0\n",
    "#    group_max = xsorted[0]\n",
    "    for i in range(0, Npt, Npt_bin):\n",
    "        group = xsorted[i:i + Npt_bin] # Select a group with Npt_bin elements\n",
    "#        group_min = group_max\n",
    "#        group_max = np.max(group)\n",
    "        group_min = group[0]\n",
    "        if i+Npt_bin+1 < Npt -1 :\n",
    "            group_max = xsorted[i+Npt_bin+1]\n",
    "        else :\n",
    "            group_max = xsorted[Npt -1]            \n",
    "        bins.append(group_max)\n",
    "        bin_width = group_max - group_min # bins [a,b] implies a <= x < b, except for last bin\n",
    "        Histo_array.append([group_max, group_min, bin_width])\n",
    "    Histo_array = np.array(Histo_array)\n",
    "    Mode_array = Histo_array[Histo_array[:, 2].argsort()]  # bin_width has index 2\n",
    "\n",
    "    # All bins have the same value of Npt_bin, hence points up to reach the desired probability\n",
    "    total_prob = 0.\n",
    "    nbins_i = 0\n",
    "    for element in Mode_array:\n",
    "        total_prob += Npt_bin\n",
    "        nbins_i += 1\n",
    "        if total_prob / Npt >= Qcl: \n",
    "            break\n",
    "\n",
    "    x_top = np.max(Mode_array[:nbins_i,0])\n",
    "    x_bottom = np.min(Mode_array[:nbins_i,1])\n",
    "    x_mode = (Mode_array[0,0] + Mode_array[0,1])/2\n",
    "\n",
    "    print(f\"     SUMMARIES    \")\n",
    "    print(f\" 1) mean   = {xmean:.4f}, sigma     = {xstd:.4f}; (mean - sigma = {(xmean-xstd):.4f}; mean - sigma = {(xmean+xstd):.4f}; )\")\n",
    "    print(f\" 2) median = {xmedian:.4f}, Q{(0.5 - (Qmedian/2.)):.2f}     = {xQlow:.4f}, Q{(0.5 + (Qmedian/2.)):.2f}     = {xQup:.4f}\")\n",
    "    print(f\" 3) mode   = {x_mode:.4f}, LowCL{Qcl:.2f} = {x_bottom:.4f}, upCL{Qcl:.2f} = {x_top:.4f}\")\n",
    "    print(f\"     Test:    \")\n",
    "    print(f\"mode-median-mean:  mode - median = {(x_mode - xmedian):.4f}   median - mean = {((xmedian-xmean)):.4f}\")\n",
    "    print(f\"Dooson 1917:  mode - mean = {(x_mode - xmean):.4f}   3(median - mean) = {(3.*(xmedian-xmean)):.4f}\")\n",
    "    print(f\"    \")\n",
    "\n",
    "    # Plot\n",
    "    # Data with equal bins\n",
    "    # plt.hist(xsorted, bins = bins, edgecolor='black', alpha=0.7) \n",
    "\n",
    "    frec = []\n",
    "    frec = Npt_bin/Histo_array[:,2]/Npt\n",
    "    frec = np.array(frec)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(xsize, ysize))\n",
    "    axes[0].hist(xdata, bins=Nbins, color='orange',alpha=0.4, edgecolor='black',density=True)\n",
    "    axes[1].bar (Histo_array[:,0], frec, width=Histo_array[:,1]-Histo_array[:,0], align='edge', color='violet', edgecolor='black',alpha=0.4)\n",
    "\n",
    "    \n",
    "#    plt.bar(inf, frec, width=Histo_array[:,2], aling='edge', ec='white')\n",
    "#    plt.xticks(np.concatenate((Histo_array[:,0], Histo_array[:,1])))\n",
    "    # Mean\n",
    "    axes[0].axvline(xmean, color='black', linestyle='--', linewidth=4, label=\"Mean\")\n",
    "    axes[1].axvline(xmean, color='black', linestyle='--', linewidth=4, label=\"Mean\")\n",
    "    # Median and Quatile\n",
    "    xmin, xmax = xQlow, xQup\n",
    "    axes[0].axvspan(xmin, xmax, color='red', alpha=0.1, label=\"Quartile area\")\n",
    "    axes[0].axvline(xmedian, color='red', linestyle='--', linewidth=2, label=\"Median\")\n",
    "    axes[1].axvline(xmedian, color='red', linestyle='--', linewidth=2, label=\"Median\")\n",
    "    axes[1].axvline(xmin, color='red', linestyle='--', alpha=0.3, label=\"Quartile area\")\n",
    "    axes[1].axvline(xmax, color='red', linestyle='--', alpha=0.3)\n",
    "\n",
    "    # Mode and CL\n",
    "    xmin, xmax = x_bottom, x_top\n",
    "    axes[0].axvline(x_mode, color='blue', linestyle='--', linewidth=2, label=\"Mode\")\n",
    "    axes[0].axvline(xmin, color='blue', linestyle='--', alpha=0.3, label=\"CL area\")\n",
    "    axes[0].axvline(xmax, color='blue', linestyle='--', alpha=0.3)\n",
    "    axes[1].axvline(x_mode, color='blue', linestyle='--', linewidth=2, label=\"Mode\")\n",
    "    axes[1].axvspan(xmin, xmax, color='blue', alpha=0.1, label=\"CL area\")\n",
    "\n",
    "\n",
    "    # Configurar los minor ticks en ambos ejes\n",
    "    axes[0].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[0].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "    axes[1].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[1].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "\n",
    "    # Activar los minor ticks en los bordes superior y derecho\n",
    "    axes[0].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[0].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "    axes[1].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[1].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "\n",
    "    \n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[1].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"frecuency\")\n",
    "    axes[1].set_ylabel(\"frecuency\")\n",
    "    \n",
    "    if xlog : \n",
    "        axes[0].set_xscale('log')\n",
    "        axes[1].set_xscale('log')\n",
    "    if ylog : \n",
    "        axes[0].set_yscale('log')\n",
    "        axes[1].set_yscale('log')\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    axes[0].set_title(title)\n",
    "    axes[1].set_title(title)\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "    return  xmean, xstd, xmedian, xQlow, xQup, x_mode, x_bottom, x_top\n",
    "\n",
    "# Añadimos etiquetas y mostramos el gráfico\n",
    "#plt.xlabel(\"Puntos\")\n",
    "#plt.ylabel(\"Frecuencia\")\n",
    "#plt.title(\"Histograma Personalizado\")\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4ea93-e818-405e-9965-a240a15dc987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlawFUN(x,LeftX,RightX,slope):\n",
    "    if LeftX > RightX :\n",
    "        print(f\"Error: Lower Limit > Upper limit\")\n",
    "        #raise Exception('Error: Lower Limit > Upper limit')\n",
    "        sys.exit()\n",
    "    xlow = LeftX\n",
    "    xup = RightX\n",
    "    alpha = slope\n",
    "\n",
    "    if(np.abs(alpha + 1.) > 1.e-7) :\n",
    "        Anorm = (np.power(xup,alpha + 1.) - np.power(xlow,alpha + 1.))/(alpha + 1.)\n",
    "        Anorm = 1. / Anorm\n",
    "    else :\n",
    "        Anorm = np.log(xup/xlow)\n",
    "        Anorm = 1. / Anorm\n",
    "    return Anorm * np.power(x,slope)\n",
    "\n",
    "\n",
    "def powerlawPDF(LeftX,RightX,slope,nMon = 100000):\n",
    "    z = np.random.uniform(0.0, 1.0, nMon)\n",
    "    xlow = LeftX\n",
    "    xup = RightX\n",
    "    alpha = slope\n",
    "    if LeftX > RightX :\n",
    "        print(f\"Error: Lower Limit > Upper limit\")\n",
    "        #raise Exception('Error: Lower Limit > Upper limit')\n",
    "        sys.exit()\n",
    "    if(np.abs(alpha + 1.) > 1.e-7) :\n",
    "        Anorm = (np.power(xup,alpha + 1.) - np.power(xlow,alpha + 1.))/(alpha + 1.)\n",
    "        Anorm = 1. / Anorm\n",
    "        x = np.power( (z * (alpha+1.) / Anorm) + np.power(xlow, alpha +1.), 1./(alpha + 1.))\n",
    "    else :\n",
    "        Anorm = np.log(xup/xlow)\n",
    "        Anorm = 1. / Anorm\n",
    "        x = xlow * np.exp(z / Anorm)\n",
    "    return x\n",
    "\n",
    "def powerlawMomentsAndQantiles(LeftX,RightX,slope,Qmedian): \n",
    "    xlow = LeftX\n",
    "    xup = RightX\n",
    "    alpha = slope\n",
    "    if LeftX > RightX :\n",
    "        print(f\"Error: Lower Limit > Upper limit\")\n",
    "        #raise Exception('Error: Lower Limit > Upper limit')\n",
    "        sys.exit()\n",
    "\n",
    "    if(np.abs(alpha + 1.) > 1.e-7) :\n",
    "        Anorm = (np.power(xup,alpha + 1.) - np.power(xlow,alpha + 1.))/(alpha + 1.)\n",
    "        Anorm = 1. / Anorm\n",
    "    else :\n",
    "        Anorm = np.log(xup/xlow)\n",
    "        Anorm = 1. / Anorm\n",
    "\n",
    "    if(np.abs(alpha + 2.) > 1.e-7) :    \n",
    "        xmean = Anorm * (np.power(xup,alpha + 2.) - np.power(xlow,alpha + 2.))/(alpha + 2.)\n",
    "    else:\n",
    "        xmean = Anorm * np.log(xup/xlow)\n",
    "\n",
    "    if(np.abs(alpha + 3.) > 1.e-7) :    \n",
    "        xstd = Anorm * (np.power(xup,alpha + 3.) - np.power(xlow,alpha + 3.))/(alpha + 3.)\n",
    "    else:\n",
    "        xstd = Anorm * np.log(xup/xlow)\n",
    "    \n",
    "    xstd = np.sqrt(xstd - (xmean*xmean))\n",
    "    print(f\" Analitical values: mean   = {xmean:.4f},   sigma = {xstd:.4f};\")\n",
    "    \n",
    "    #Quantiles\n",
    "    xQ = empty(3)\n",
    "    xQ[0] = 0.5 - (Qmedian / 2.)\n",
    "    xQ[1] = 0.5 \n",
    "    xQ[2] = 0.5 + ( Qmedian / 2.)\n",
    "\n",
    "    xOUT = empty(3)\n",
    "    for i in range(0,3):\n",
    "        if(np.abs(alpha + 1.) > 1.e-7) :\n",
    "            xOUT[i] = np.power( (xQ[i] * (alpha+1.) / Anorm) + np.power(xlow, alpha +1.), 1./(alpha + 1.))\n",
    "        else :\n",
    "            xOUT[i] = xlow * np.exp(xQ[i]/ Anorm)\n",
    "\n",
    "    print(f\"                    median = {xOUT[1]:.4f}, Q{(0.5 - (Qmedian/2.)):.2f}   = {xOUT[0]:.4f}, Q{(0.5 + (Qmedian/2.)):.2f} = {xOUT[2]:.4f}\")\n",
    "    return xmean, xstd, xOUT[1],xOUT[0],xOUT[2]\n",
    "\n",
    "\n",
    "def powerlawPLOT(LeftX,RightX,slope, nMon = 100000, Nbins = 20, xlog=False, ylog=False, title=' ',xsize=12,ysize=5):\n",
    "    xdata = powerlawPDF(LeftX,RightX,slope, nMon = nMon)\n",
    "    xmin_plot = np.min(xdata)\n",
    "    xmax_plot = np.max(xdata)\n",
    "\n",
    "    # 1) sort array\n",
    "    Npt = int(len(xdata))\n",
    "    xsorted = np.take_along_axis(xdata,np.argsort(xdata),axis=0)\n",
    "\n",
    "    # Mode an Intervals (assuming Nbins bins (20 by default)  and Npt is multiple of Nbins)\n",
    "    Npt_bin = int(Npt / Nbins)\n",
    "\n",
    "    Histo_array = []\n",
    "    bins = []\n",
    "    bins.append(xsorted[0])\n",
    "    group_max =xsorted[0]\n",
    "    for i in range(0, Npt, Npt_bin):\n",
    "        group = xsorted[i:i + Npt_bin] # Select a group with Npt_bin elements\n",
    "        group_min = group_max\n",
    "        group_max = np.max(group)\n",
    "        bins.append(group_max)\n",
    "        bin_width = group_max - group_min # bins [a,b] implies a <= x < b, except for last bin\n",
    "        Histo_array.append([group_max, group_min, bin_width])\n",
    "    Histo_array = np.array(Histo_array)\n",
    "    Mode_array = Histo_array[Histo_array[:, 2].argsort()]  # bin_width has index 2\n",
    "\n",
    "    # Plot\n",
    "    # Data with equal bins\n",
    "    # plt.hist(xsorted, bins = bins, edgecolor='black', alpha=0.7) \n",
    "\n",
    "    frec = []\n",
    "    frec = Npt_bin/Histo_array[:,2]/Npt\n",
    "    frec = np.array(frec)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(xsize, ysize))\n",
    "    axes[0].hist(xdata, bins=Nbins, color='orange',alpha=0.4, edgecolor='black',density=True)\n",
    "    axes[1].bar (Histo_array[:,0], frec, width=Histo_array[:,1]-Histo_array[:,0], align='edge', color='violet', edgecolor='black',alpha=0.4)\n",
    "\n",
    "    x = np.linspace(xmin_plot,xmax_plot,100)\n",
    "    axes[0].plot(x,powerlawFUN(x,LeftX,RightX,slope),'r',alpha=0.6)\n",
    "    axes[1].plot(x,powerlawFUN(x,LeftX,RightX,slope),'r',alpha=0.6)\n",
    "\n",
    "    \n",
    "    # Configurar los minor ticks en ambos ejes\n",
    "    axes[0].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[0].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "    axes[1].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[1].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "\n",
    "    # Activar los minor ticks en los bordes superior y derecho\n",
    "    axes[0].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[0].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "    axes[1].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[1].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[1].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"frecuency\")\n",
    "    axes[1].set_ylabel(\"frecuency\")\n",
    "    \n",
    "    if xlog : \n",
    "        axes[0].set_xscale('log')\n",
    "        axes[1].set_xscale('log')\n",
    "    if ylog : \n",
    "        axes[0].set_yscale('log')\n",
    "        axes[1].set_yscale('log')\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    axes[1].set_title(title)\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "    return  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08feb4d-c269-4ee9-8190-abd2c4aabf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangularFUN(x,LeftX,MaxX,RightX):\n",
    "    x0 = MaxX\n",
    "    a = LeftX\n",
    "    b = RightX\n",
    "    if LeftX > RightX :\n",
    "        print(f\"Error: Lower Limit > Upper limit\")\n",
    "        #raise Exception('Error: Lower Limit > Upper limit')\n",
    "        sys.exit()\n",
    "    if x0 > RightX :\n",
    "        print(f\"Error: Triangle Vertice > Upper limit\")\n",
    "        sys.exit()\n",
    "    if x0 < LeftX :\n",
    "        print(f\"Error: Triangle Vertice < Lower limit\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Opcion  1 use scipy.stats\n",
    "    # Convertir a la escala de scipy (c es la ubicación del modo en el intervalo [0, 1])\n",
    "    # c = (x0 - a) / (b - a)\n",
    "    # return triang.pdf(x, c, loc= a, scale = b - a)\n",
    "    \n",
    "    conditions = [\n",
    "        x < LeftX ,\n",
    "        (x >= LeftX) & (x < MaxX), \n",
    "        (x >= MaxX) & (x <= RightX),\n",
    "        x > RightX\n",
    "    ]\n",
    "        \n",
    "    h = 2./(b-a)\n",
    "    functions = [\n",
    "        lambda x: 0.,\n",
    "        lambda x: h * ( x - a) / (MaxX -a),\n",
    "        lambda x: h * ( b - x ) / (b - MaxX),\n",
    "        lambda x: 0.\n",
    "    ]\n",
    "        \n",
    "    return np.piecewise(x, conditions, functions)\n",
    "        \n",
    "\n",
    "def triangularPDF(LeftX,MaxX,RightX,nMon = 100000):\n",
    "    z = np.random.uniform(0.0, 1.0, nMon)\n",
    "    x = empty(nMon)\n",
    "    x0 = MaxX\n",
    "    a = LeftX\n",
    "    b = RightX\n",
    "    if LeftX > RightX :\n",
    "        print(f\"Error: Lower Limit > Upper limit\")\n",
    "        #raise Exception('Error: Lower Limit > Upper limit')\n",
    "        sys.exit()\n",
    "    if x0 > RightX :\n",
    "        print(f\"Error: Triangle Vertice > Upper limit\")\n",
    "        sys.exit()\n",
    "    if x0 < LeftX :\n",
    "        print(f\"Error: Triangle Vertice < Lower limit\")\n",
    "        sys.exit()\n",
    "    h = 2./(b-a)\n",
    "    for i in range(nMon):\n",
    "        if (h*(x0-a)/2.)  >= z[i]:\n",
    "            x[i] = a + np.sqrt(((2.*(x0-a)*z[i])/h))\n",
    "        else:\n",
    "            x[i] = b - np.sqrt( (b-x0)*(b-x0) - ((2.*(b-x0)*(z[i]-((h*(x0-a))/2.)))/h))\n",
    "        if( x[i] <= a ):\n",
    "            print(\"Error!! Thisn never must happen!!\")\n",
    "            sys.exit()\n",
    "    return x\n",
    "\n",
    "def triangularMomentsAndQantiles(LeftX,MaxX,RightX,Qmedian): \n",
    "    if LeftX > RightX :\n",
    "        print(f\"Error: Lower Limit > Upper limit\")\n",
    "        #raise Exception('Error: Lower Limit > Upper limit')\n",
    "        sys.exit()\n",
    "    if MaxX > RightX :\n",
    "        print(f\"Error: Triangle Vertice > Upper limit\")\n",
    "        sys.exit()\n",
    "    if MaxX < LeftX :\n",
    "        print(f\"Error: Triangle Vertice < Lower limit\")\n",
    "        sys.exit()\n",
    "    \n",
    "    #Moments: D'Agostini & Raso 2000 https://arxiv.org/pdf/hep-ex/0002056v1\n",
    "    DeltaXminus = MaxX -  LeftX\n",
    "    DeltaXplus = RightX - MaxX \n",
    "    xmean = MaxX + (DeltaXplus - DeltaXminus) / 3.\n",
    "    xstd = ((DeltaXplus * DeltaXplus) + (DeltaXminus*DeltaXminus) + DeltaXplus*DeltaXminus) / 18.\n",
    "    xstd = np.sqrt(xstd)\n",
    "    print(f\" Analitical values: mean   = {xmean:.4f},   sigma = {xstd:.4f};\")\n",
    "\n",
    "    #Quantiles\n",
    "    xQ = empty(3)\n",
    "    xQ[0] = 0.5 - (Qmedian / 2.)\n",
    "    xQ[1] = 0.5 \n",
    "    xQ[2] = 0.5 + ( Qmedian / 2.)\n",
    "\n",
    "    x0 = MaxX\n",
    "    a = LeftX\n",
    "    b = RightX\n",
    "    h = 2./(b-a)\n",
    "\n",
    "    xOUT = empty(3)\n",
    "    for i in range(0,3):\n",
    "        if (h*(x0-a)/2.)  >= xQ[i]:\n",
    "            xOUT[i] = a + np.sqrt(((2.*(x0-a)*xQ[i])/h))\n",
    "        else:\n",
    "            xOUT[i] = b - np.sqrt( (b-x0)*(b-x0) - ((2.*(b-x0)*(xQ[i]-((h*(x0-a))/2.)))/h))\n",
    "    print(f\"                    median = {xOUT[1]:.4f}, Q{(0.5 - (Qmedian/2.)):.2f}   = {xOUT[0]:.4f}, Q{(0.5 + (Qmedian/2.)):.2f} = {xOUT[2]:.4f}\")\n",
    "    return xmean, xstd, xOUT[1],xOUT[0],xOUT[2]\n",
    "\n",
    "\n",
    "\n",
    "#Plot histogram, obtain, mean, varinace, median, 90%Q, mode, 90%CL\n",
    "def triangularPLOT(LeftX,MaxX,RightX, nMon = 100000, Nbins = 20, xlog=False, ylog=False, title=' ',xsize=12,ysize=5):\n",
    "    xdata = triangularPDF(LeftX,MaxX,RightX, nMon)\n",
    "    xmin_plot = np.min(xdata)\n",
    "    xmax_plot = np.max(xdata)\n",
    "\n",
    "    # 1) sort array\n",
    "    Npt = int(len(xdata))\n",
    "    xsorted = np.take_along_axis(xdata,np.argsort(xdata),axis=0)\n",
    "\n",
    "    # Mode an Intervals (assuming 20 bins and Npt is multiple by 20)\n",
    "    #    Nbins = 20\n",
    "    Npt_bin = int(Npt / Nbins)\n",
    "\n",
    "    Histo_array = []\n",
    "    bins = []\n",
    "    bins.append(xsorted[0])\n",
    "    group_max =xsorted[0]\n",
    "    for i in range(0, Npt, Npt_bin):\n",
    "        group = xsorted[i:i + Npt_bin] # Select a group with Npt_bin elements\n",
    "        group_min = group_max\n",
    "        group_max = np.max(group)\n",
    "        bins.append(group_max)\n",
    "        bin_width = group_max - group_min # bins [a,b] implies a <= x < b, except for last bin\n",
    "        Histo_array.append([group_max, group_min, bin_width])\n",
    "    Histo_array = np.array(Histo_array)\n",
    "    Mode_array = Histo_array[Histo_array[:, 2].argsort()]  # bin_width has index 2\n",
    "\n",
    "    # Plot\n",
    "    # Data with equal bins\n",
    "    # plt.hist(xsorted, bins = bins, edgecolor='black', alpha=0.7) \n",
    "\n",
    "    frec = []\n",
    "    frec = Npt_bin/Histo_array[:,2]/Npt\n",
    "    frec = np.array(frec)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(xsize, ysize))\n",
    "    axes[0].hist(xdata, bins=Nbins, color='orange',alpha=0.4, edgecolor='black',density=True)\n",
    "    axes[1].bar (Histo_array[:,0], frec, width=Histo_array[:,1]-Histo_array[:,0], align='edge', color='violet', edgecolor='black',alpha=0.4)\n",
    "\n",
    "    x = np.linspace(xmin_plot,xmax_plot,100)\n",
    "    axes[0].plot(x,triangularFUN(x,LeftX,MaxX,RightX),'r',alpha=0.6)\n",
    "    axes[1].plot(x,triangularFUN(x,LeftX,MaxX,RightX),'r',alpha=0.6)\n",
    "    \n",
    "    # Configurar los minor ticks en ambos ejes\n",
    "    axes[0].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[0].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "    axes[1].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[1].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "\n",
    "    # Activar los minor ticks en los bordes superior y derecho\n",
    "    axes[0].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[0].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "    axes[1].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[1].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[1].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"frecuency\")\n",
    "    axes[1].set_ylabel(\"frecuency\")\n",
    "    \n",
    "    if xlog : \n",
    "        axes[0].set_xscale('log')\n",
    "        axes[1].set_xscale('log')\n",
    "    if ylog : \n",
    "        axes[0].set_yscale('log')\n",
    "        axes[1].set_yscale('log')\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    axes[1].set_title(title)\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f5dc2-1880-4bca-9f9e-2827944c476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def splitnormalFUN(x,moda,sigma_left,sigma_right):\n",
    "    mode = moda\n",
    "    s_l = sigma_left\n",
    "    s_r = sigma_right\n",
    "\n",
    "    conditions = [\n",
    "        x < moda ,\n",
    "        x >= moda\n",
    "    ]\n",
    "\n",
    "    Anorm = np.sqrt(2./math.pi)*(1./(s_l+s_r))\n",
    "    functions = [\n",
    "        lambda x: Anorm * np.exp(-(x - moda)*(x - moda)/(2.*s_l*s_l)),\n",
    "        lambda x: Anorm * np.exp(-(x - moda)*(x - moda)/(2.*s_r*s_r))\n",
    "    ]\n",
    "        \n",
    "    return np.piecewise(x, conditions, functions)\n",
    "        \n",
    "\n",
    "def splitnormalPDF(moda,sigma_left,sigma_right,nMon = 100000):\n",
    "    # Slipt normal definition: (sqrt(2/pi))*(1/(sig1+sig2) * exp (x-mode(/2sigma_i^2) where sigma_i varies if it is right or left the mode\n",
    "    # Integral -inf up to x left mode: sig1*(1+Erf[(x-mu)/(sig1*sqrt2)]) /  (sig1+sig2)\n",
    "    # Integral up to mu: sig1/(sig1+sig2) It is de ficudal CDF value\n",
    "    # Integral up tu x right mode: (sig1/(sig1+sig2)) + sig2*Erf[(x-mu)/(sig1*sqrt2)] / (sig1+sig2) =\n",
    "    #                              (sig1+sig2*Erf[(x-mu)/(sig1*sqrt2)]) /  (sig1+sig2)\n",
    "\n",
    "    z = np.random.uniform(0.0, 1.0, nMon)\n",
    "    x = empty(nMon)\n",
    "\n",
    "    for i in range(nMon):\n",
    "        if (sigma_left/(sigma_left+sigma_right))  >= z[i]:\n",
    "            x[i] = (z[i]*(sigma_left+sigma_right)/sigma_left) - 1.\n",
    "            x[i] = moda + (np.sqrt(2.)*sigma_left)*erfinv(x[i])\n",
    "        else:\n",
    "            x[i] = (z[i]*(sigma_left+sigma_right) - sigma_left)/sigma_right\n",
    "            x[i] = moda + (np.sqrt(2.)*sigma_right)*erfinv(x[i])\n",
    "\n",
    "    return x\n",
    "    \n",
    "def splitnormalMomentsAndQantiles(moda,sigma_left,sigma_right,Qmedian):\n",
    "    xmean = moda + (np.sqrt(2./math.pi) * (sigma_right - sigma_left))\n",
    "    variance = (1. - (2./math.pi))*(sigma_right - sigma_left)*(sigma_right - sigma_left) + (sigma_right * sigma_left)\n",
    "    xstd = np.sqrt(variance)\n",
    "    \n",
    "    print(f\" Analitical values: mean   = {xmean:.4f},   sigma = {xstd:.4f};\")\n",
    "\n",
    "    #Quantiles\n",
    "    xQ = empty(3)\n",
    "    xQ[0] = 0.5 - (Qmedian / 2.)\n",
    "    xQ[1] = 0.5 \n",
    "    xQ[2] = 0.5 + ( Qmedian / 2.)\n",
    "\n",
    "    xOUT = empty(3)\n",
    "    for i in range(0,3):\n",
    "        if (sigma_left/(sigma_left+sigma_right))  >= xQ[i]:\n",
    "            xOUT[i] = (xQ[i]*(sigma_left+sigma_right)/sigma_left) - 1.\n",
    "            xOUT[i] = moda + (np.sqrt(2.)*sigma_left)*erfinv(xOUT[i])\n",
    "        else:\n",
    "            xOUT[i] = (xQ[i]*(sigma_left+sigma_right) - sigma_left)/sigma_right\n",
    "            xOUT[i] = moda + (np.sqrt(2.)*sigma_right)*erfinv(xOUT[i])\n",
    "\n",
    "    \n",
    "    print(f\"                    median = {xOUT[1]:.4f}, Q{(0.5 - (Qmedian/2.)):.2f}   = {xOUT[0]:.4f}, Q{(0.5 + (Qmedian/2.)):.2f} = {xOUT[2]:.4f}\")\n",
    "    return xmean, xstd, xOUT[1],xOUT[0],xOUT[2]\n",
    "\n",
    "#Plot histogram, obtain, mean, varinace, median, 90%Q, mode, 90%CL\n",
    "def splitnormalPLOT(moda,sigma_left,sigma_right, nMon = 100000, Nbins = 20, xlog=False, ylog=False, title=' ',xsize=12,ysize=5):\n",
    "    xdata = splitnormalPDF(moda,sigma_left,sigma_right,nMon)\n",
    "    xmin_plot = np.min(xdata)\n",
    "    xmax_plot = np.max(xdata)\n",
    "    \n",
    "    # 1) sort array\n",
    "    Npt = int(len(xdata))\n",
    "    xsorted = np.take_along_axis(xdata,np.argsort(xdata),axis=0)\n",
    "\n",
    "    # Mode an Intervals (assuming 20 bins and Npt is multiple by 20)\n",
    "    #    Nbins = 20\n",
    "    Npt_bin = int(Npt / Nbins)\n",
    "\n",
    "    Histo_array = []\n",
    "    bins = []\n",
    "    bins.append(xsorted[0])\n",
    "    group_max =xsorted[0]\n",
    "    for i in range(0, Npt, Npt_bin):\n",
    "        group = xsorted[i:i + Npt_bin] # Select a group with Npt_bin elements\n",
    "        group_min = group_max\n",
    "        group_max = np.max(group)\n",
    "        bins.append(group_max)\n",
    "        bin_width = group_max - group_min # bins [a,b] implies a <= x < b, except for last bin\n",
    "        Histo_array.append([group_max, group_min, bin_width])\n",
    "    Histo_array = np.array(Histo_array)\n",
    "    Mode_array = Histo_array[Histo_array[:, 2].argsort()]  # bin_width has index 2\n",
    "\n",
    "    # Plot\n",
    "    # Data with equal bins\n",
    "    # plt.hist(xsorted, bins = bins, edgecolor='black', alpha=0.7) \n",
    "\n",
    "    frec = []\n",
    "    frec = Npt_bin/Histo_array[:,2]/Npt\n",
    "    frec = np.array(frec)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(xsize, ysize))\n",
    "    axes[0].hist(xdata, bins=Nbins, color='orange',alpha=0.4, edgecolor='black',density=True)\n",
    "    axes[1].bar (Histo_array[:,0], frec, width=Histo_array[:,1]-Histo_array[:,0], align='edge', color='violet', edgecolor='black',alpha=0.4)\n",
    "\n",
    "    \n",
    "    x = np.linspace(xmin_plot,xmax_plot,100)\n",
    "    axes[0].plot(x,splitnormalFUN(x,moda,sigma_left,sigma_right),'r',alpha=0.6)\n",
    "    axes[1].plot(x,splitnormalFUN(x,moda,sigma_left,sigma_right),'r',alpha=0.6)\n",
    "\n",
    "    \n",
    "    # Configurar los minor ticks en ambos ejes\n",
    "    axes[0].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[0].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "    axes[1].xaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje x\n",
    "    axes[1].yaxis.set_minor_locator(AutoMinorLocator(2))  # Minor ticks en el eje y\n",
    "\n",
    "    # Activar los minor ticks en los bordes superior y derecho\n",
    "    axes[0].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[0].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "    axes[1].tick_params(which='both', direction='in', top=True, right=True)         # Activar ticks en top y right\n",
    "    axes[1].tick_params(which='minor', length=4, color='gray')      # Configurar minor ticks\n",
    "\n",
    "    axes[0].set_xlabel(\"X\")\n",
    "    axes[1].set_xlabel(\"X\")\n",
    "    axes[0].set_ylabel(\"frecuency\")\n",
    "    axes[1].set_ylabel(\"frecuency\")\n",
    "    \n",
    "    if xlog : \n",
    "        axes[0].set_xscale('log')\n",
    "        axes[1].set_xscale('log')\n",
    "    if ylog : \n",
    "        axes[0].set_yscale('log')\n",
    "        axes[1].set_yscale('log')\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    axes[1].set_title(title)\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()\n",
    "\n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f41bfc-4b62-40b2-8652-c3ca3748f727",
   "metadata": {},
   "source": [
    "## 1. Representations of Uncertainty (PDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78b0e9-643f-4636-8e82-e7336ba5d7b2",
   "metadata": {},
   "source": [
    "There are lots of probability distributions, they aims to describe the _possible_ otucomes of a process and are called Prbability Density Distributions, PDFs. Examples are the Mawell-Boltzmann distribution, the Initial Mass Function, Gaussian distributions, Poison distributions and so on.\n",
    "\n",
    "The idea is describe the probability that a event (or a parameter or whatever you want) is enclosed in a given range. In general each PDF is linked with the particular process they describe: Poison work for photon counting, Gaussian for realeated independent measurements, Mawell-Boltzmann for free electorns, IMF for stellar masses and so on.\n",
    "\n",
    "Let us assume a few cases cases of asimetric distributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e40fa-9341-4cbd-9c32-9c4449d01618",
   "metadata": {},
   "source": [
    "- a PowerLaw PDF (as the IMF) with limits $x_\\mathrm{min}$, $x_\\mathrm{max}$, and exponet $\\alpha$ (with $\\alpha \\neq -1$)\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\varphi_1(x) &=& \\frac{\\alpha -1}{x_\\mathrm{max}^{\\alpha +1} - x_\\mathrm{min}^{\\alpha +1}} \\, \\,  x^\\alpha \\\\\n",
    "\\mathrm{CDF}[\\varphi_1(x)] = z = \\int_{-\\infty}^x \\varphi_1(x) \\, \\mathrm{d}x &=& \\frac{\\alpha -1}{x_\\mathrm{max}^{\\alpha +1} - x_\\mathrm{min}^{\\alpha +1}} \\frac{x^{\\alpha+1} - x_\\mathrm{min}^{\\alpha+1}}{\\alpha+1} = \\frac{x^{\\alpha+1} - x_\\mathrm{min}^{\\alpha+1}}{x_\\mathrm{max}^{\\alpha +1} - x_\\mathrm{min}^{\\alpha +1}}\\\\\n",
    "x &=& (z \\times (x_\\mathrm{max}^{\\alpha +1} - x_\\mathrm{min}^{\\alpha +1}) + x_\\mathrm{min}^{\\alpha+1} )^\\frac{1}{\\alpha + 1}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388cf91-df5c-4950-af91-05327029360e",
   "metadata": {},
   "source": [
    "- a <a href=\"https://en.wikipedia.org/wiki/Triangular_distribution\">Triangular PDF</a> which begins at point $(a,0)$, has a maximun at $(\\hat{x},h)$ and ends at point $(b,0)$, so $h = 2/(b-a)$ to keep the total area equal to 1.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\varphi_2(x) &=&\n",
    "    \\begin{cases}\n",
    "        \\frac{h}{\\hat{x}-a} \\, (x- a) & \\text{if } x < \\hat{x}\\\\\n",
    "        \\frac{h}{b-\\hat{x}} \\, (b - x) & \\text{if } x \\geq \\hat{x}\n",
    "    \\end{cases} \\\\\n",
    "\\mathrm{CDF}[\\varphi_2(x)] = z = \\int_{-\\infty}^x \\varphi_2(x) \\, \\mathrm{d}x &=&\n",
    "    \\begin{cases}\n",
    "        \\frac{h}{2\\, (\\hat{x}-a)} \\, (x-a)^2  & \\text{if } x < \\hat{x}\\\\\n",
    "        \\frac{h\\, (\\hat{x}-a)}{2} - \\frac{h}{2\\,(b-\\hat{x})} ((b-\\hat{x})^2 - (b-x)^2) & \\text{if } x \\geq \\hat{x}\n",
    "    \\end{cases} \\\\\n",
    "x &=&\n",
    "    \\begin{cases}\n",
    "        a + \\sqrt{\\frac{2\\, (\\hat{x}-a)\\, z}{h}}  & \\text{if } z <  \\frac{h\\, (\\hat{x}-a)}{2}\\\\\n",
    "        b - \\sqrt{(b-\\hat{x})^2 - \\frac{2\\, (b-\\hat{x})\\, \\left(z - \\frac{h\\, (\\hat{x}-a)}{2}\\right)}{h}} & \\text{if } z \\geq \\frac{h\\, (\\hat{x}-a)}{2}\n",
    "    \\end{cases} \\\\\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c60bb-12ae-45a0-bb01-c2f122c8ebd6",
   "metadata": {},
   "source": [
    "- a <a href=\"https://en.wikipedia.org/wiki/Split_normal_distribution\">Slipt-normal PDF</a> which is a two normal distributions with diferent dispersion at the left ($\\sigma_\\mathrm{l}$) and right ($\\sigma_\\mathrm{r}$) of a given value $\\hat{m}$.\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\varphi_3(x) &=&\n",
    "    \\begin{cases}\n",
    "        \\sqrt{\\frac{2}{\\pi}}\\,\\frac{1}{\\sigma_\\mathrm{l}+\\sigma_\\mathrm{r}} \\,\\, \\exp \\left( - \\frac{(x-\\hat{m})^2}{2\\,\\sigma_\\mathrm{l}^2} \\right) & \\text{if } x < \\hat{m}\\\\\n",
    "        \\sqrt{\\frac{2}{\\pi}}\\,\\frac{1}{\\sigma_\\mathrm{l}+\\sigma_\\mathrm{r}} \\,\\, \\exp \\left( - \\frac{(x-\\hat{m})^2}{2\\,\\sigma_\\mathrm{r}^2} \\right)  & \\text{if } x \\geq \\hat{m}\n",
    "    \\end{cases} \\\\\n",
    "\\mathrm{CDF}[\\varphi_3(x)] = z = \\int_{-\\infty}^x \\varphi_1(x) \\, \\mathrm{d}x = &=&\n",
    "    \\begin{cases}\n",
    "        \\frac{\\sigma_\\mathrm{l}}{\\sigma_\\mathrm{l} + \\sigma_\\mathrm{r}} ( 1 + \\mathrm{Erf}\\left[\\frac{x-\\hat{m}}{\\sqrt{2} \\sigma_\\mathrm{l}}\\right] ) & \\text{if } x < \\hat{m}\\\\\n",
    "        \\frac{1}{\\sigma_\\mathrm{l} + \\sigma_\\mathrm{r}} ( \\sigma_\\mathrm{l} + \\sigma_\\mathrm{r} \\,\\mathrm{Erf}\\left[\\frac{x-\\hat{m}}{\\sqrt{2} \\sigma_\\mathrm{r} }\\right] ) & \\text{if } x \\geq \\hat{m}\n",
    "    \\end{cases} \\\\\n",
    "x &=&\n",
    "    \\begin{cases}\n",
    "        \\hat{m} + \\sqrt{2}\\,\\sigma_\\mathrm{l}\\, \\mathrm{Erf}\\left[\\frac{z  (\\sigma_\\mathrm{l} + \\sigma_\\mathrm{r})}{\\sigma_\\mathrm{l}} - 1\\right] & \\text{if } z < \\frac{\\sigma_1}{\\sigma_1 + \\sigma_2}  \\\\\n",
    "                \\hat{m} + \\sqrt{2}\\,\\sigma_\\mathrm{r}\\, \\mathrm{Erf}\\left[\\frac{z  (\\sigma_\\mathrm{l} + \\sigma_\\mathrm{r}) - \\sigma_\\mathrm{l}}{\\sigma_\\mathrm{r}}\\right] & \\text{if } z \\geq \\frac{\\sigma_1}{\\sigma_1 + \\sigma_2}\n",
    "    \\end{cases} \\\\\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a5cdc-4347-4cf9-ac70-5136e647a13c",
   "metadata": {},
   "source": [
    "#### How to make the representatión?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25bf84-3b31-4a04-92fc-95ae8bb56f3f",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Plot the PDF ussing the functional form</li>\n",
    "    <li>Make a simulation and plot the resulta in an Histogram with\n",
    "        <ol>\n",
    "            <li> <i>Regular bin size</i>  (but they may product empty bins &#129300;)</li>\n",
    "            <li> &#128073;  Bins wiht equal area (i.e. equal probability), which asure a continous description of the PDF and, hence, a better fit if requiered &#128571;</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<b>IMPORTANT</b>\n",
    "In histograms you must define clearly the meaning of the intervals!! (it is, the meaning of the integral limits for a continous PDFs)<br>\n",
    "\n",
    "<center>\n",
    "    They must be <font color=\"green\">$a \\le x \\lt b$</font> or <font color=\"green\">$a \\lt x \\le b$</font> but not <font color=\"red\">$a \\le x \\le b$</font>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "Example IGIMF theory by Kroupa et al. (<a href=\"https://ui.adsabs.harvard.edu/abs/2004MNRAS.348..187W/abstract\">Weidner &amp: Kroupa 2004, MNRAS 348, 187</a> and posterior works) make the incorrect use of it and assume $a \\le x \\le b$ in the integral limits, so the whole theory is mathematically incorrect <font color=\"green\" >&#129318;&#127997; </font>!!\n",
    "(see <a href=\"https://ui.adsabs.harvard.edu/abs/2013A%26A...553A..31C/abstract\">Cerviño et al. 2013, A&amp;A 553, A31</a> for details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57435450-38a6-42af-8c3a-faccc3abbf63",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d6370-238b-442a-871e-cce02141f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See more example of fitting the IMF in Maíz-Apellániz & Úbeda Ap.J. 2005, 629, 873\n",
    "powerlawPLOT(2.,120.,-2.35, Nbins=100, nMon=1000,  ylog=True, xsize=10,ysize= 4.8, title=\"powerlaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c6190-a6f9-43ba-9fcc-0b1622773bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER EXAMPLES:\n",
    "triangularPLOT(-1.,0.80,5.,xsize=5,ysize= 3, title=\"triangular\")\n",
    "\n",
    "splitnormalPLOT(3.,1.,3.,Nbins=20, nMon=100000, xsize=5,ysize= 3, title=\"splitNormal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a42e9b-5556-4203-aab2-e2a557776097",
   "metadata": {},
   "source": [
    "## 2. Measurement of location and dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec830023-ecf1-4066-b3e0-5d00b9858512",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6683bf-49a1-4cb9-8b2e-45b43cff054a",
   "metadata": {},
   "source": [
    "Work directlly with PDFs would be cumbersome, and some times we only want to have some <i>summaries</i> of the PDF $\\varphi(x)$. It is, a few <i>numbers</i> which give an idea about the distribution, and which we can use for work in further analisys. They can be called generiacally <i>central values</i> and <i>uncertainties</i>, althought there can be defined in several ways. Some of them are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4407b3-92b5-4fa4-9ff2-36161f1cef8b",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Mean, $\\mu$, and variance, $\\sigma^2$, or standard devaition, $\\sigma$ (and skwness, kurtosis and high-order raw and central moments, $\\mu'_n$ and $\\mu_n$):\n",
    "      \\begin{eqnarray}\n",
    "        \\mu'_1 = \\mu' = \\mu &=& \\int \\, x\\, \\varphi(x) \\mathrm{d}x \\\\\n",
    "        \\sigma^2 = \\mu_2 &=& \\int \\,(x-\\mu')^2 \\,\\varphi(x)\\,\\mathrm{d}x = \\left(\\int\\, x^2\\,\\varphi(x)\\,\\mathrm{d}x \\right) - {\\mu'}^2\\\\\n",
    "        \\mu'_n = \\int \\, x^n \\, \\varphi(x) \\mathrm{d}x \\,\\,\\,\\,\\,& & \\,\\,\\,\\,\\,\\mu_n = \\int \\, (x - \\mu' )^n \\, \\varphi(x) \\mathrm{d}x\n",
    "      \\end{eqnarray}\n",
    "    </li>\n",
    "    <li>Median, $\\bar{x}$ (non standard notation), and percentils Qx.x (the median is the 50% percentil, $\\bar{x} = \\mathrm{Q}0.5$). \n",
    "        It can be directlly obtained from the inversion of $\\mathrm{CDF}[\\varphi_3(x)]$\n",
    "        \\begin{eqnarray}\n",
    "          0.5 &=& \\int_{-\\infty}^{\\mathrm{\\bar{x}}} \\, \\varphi(x) \\mathrm{d}x \\\\\n",
    "          0.1 &=& \\int_{-\\infty}^{\\mathrm{Q0.1}} \\, \\varphi(x) \\mathrm{d}x \\\\\n",
    "          0.9 &=& \\int_{-\\infty}^{\\mathrm{Q0.9}} \\, \\varphi(x) \\mathrm{d}x \n",
    "        \\end{eqnarray}\n",
    "    </li>\n",
    "    <li>Mode, $\\hat{x}$ (non standard notation), and the minimun $\\Delta x$  which covers a given probability value \n",
    "        hence probailities arond the mode (here CL interval, but non standard name); ussing a probablity of 68\\% as example) \n",
    "        \\begin{eqnarray}\n",
    "          \\hat{x} & = & \\mathrm{MAX}[\\varphi(x)] \\\\\n",
    "          \\mathrm{MIN[\\Delta x (= upCL-lowCL)]} & : & 0.68  = \\int_\\mathrm{lowCL}^\\mathrm{upCL} \\, \\varphi(x) \\mathrm{d}x \n",
    "        \\end{eqnarray}\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb3254-15ca-4ec7-93dd-0ec592d8a31a",
   "metadata": {},
   "source": [
    "#### Outline for dispersion around the mode\n",
    "\n",
    "<ol>\n",
    "<li>Step 1: <i>histograms whith similar area</i>\n",
    "    <ol>\n",
    "        <li>Sort the data (similar to requerimetns to make de median)</li>\n",
    "        <li>Make $N_\\mathrm{bins}$ with $N_\\mathrm{data}/N_\\mathrm{bins}$ elements each (<i>all groups with the same number of data items, hence equal probability</i> $1/N_\\mathrm{bins}$)</li>\n",
    "        <li>Obtain the $x_{\\mathrm{min},i}$ and $x_{\\mathrm{max},i}$ of each group and the size of the bin $\\Delta x_i = x_{\\mathrm{min},i+1} - x_{\\mathrm{min},i}$, and make an array  $[x_{\\mathrm{min},i}, \\Delta x_i, x_{\\mathrm{max},i}]$. IMPORTANT: Note, that actually you must use $x_{\\mathrm{min},i+1}$ instead the nominal $x_{\\mathrm{max},i}$ value to define teh size of the bin, since bins must be defined as $x_{\\mathrm{min},i} \\le x \\lt x_{\\mathrm{min},i+1}$ and not as $x_{\\mathrm{min},i} \\le x \\le x_{\\mathrm{max},i}$; formally, $x_{\\mathrm{max},i}$ is only i¡used for the last bin. It assure continuity.</li>\n",
    "    </ol>\n",
    "<br><br>\n",
    "</li>\n",
    "<li>Step 2: <i>Probability computations</i>\n",
    "    <ol>\n",
    "        <li>Sort the array with $\\Delta x_i$ from lower to max</li>\n",
    "        <li>The first element of the sorted array contains the mode: each group have an equal probability (i.e. area), lower $\\Delta x_i$ implies larger probability of the bin</li>\n",
    "        <li>Add elements of the sorted array up to the desired probability value, keeping the $\\mathrm{min}[x_{min,i}]$ and $\\mathrm{max}[x_{max,i}]$ values to define the $\\mathrm{lowCL}$ and $\\mathrm{upCL}$ values (or intervals) </li>\n",
    "    </ol>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15b8b6-ba9c-4cd7-9317-6ce77ba6d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = powerlawPDF(1,15,-1.5)\n",
    "#xdata = triangularPDF(5.,8.,9.)\n",
    "#xdata = splitnormalPDF(2.,0.5,9.)\n",
    "\n",
    "powerlawMomentsAndQantiles(1,15,-1.5,0.68)\n",
    "#triangularMomentsAndQantiles(5.,8.,9.,0.68)\n",
    "#splitnormaMomentsAndQantiles(2.,0.5,9.,0.68)\n",
    "\n",
    "# plot_PDF provides an array with mean, std, median, Qlow, Qup, mode, CLlow, CLup\n",
    "a = []\n",
    "a = plot_PDF(xdata,0.68,0.68)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e81-e025-4dac-ab07-ae4ddd0968d3",
   "metadata": {},
   "source": [
    "### Tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584c4fe-ba26-40cd-bc8c-4f2f33646964",
   "metadata": {},
   "source": [
    "Some tricks for unimodal PDFs Kendall's Cap. 2, 2.9:\n",
    "<ul>\n",
    "<li> with <b>very moderate</b> asymmetry Doodson 1917 (<a href=\"https://www.jstor.org/stable/pdf/2331833\">https://www.jstor.org/stable/pdf/2331833</a>)\n",
    "\n",
    "\\begin{equation}\n",
    "{\\color{green}  \\mathrm{mode} - \\mu = 3 (\\mathrm{median} - \\mu)}\n",
    "\\end{equation}\n",
    "\n",
    "Interstingly, the modal filter used by IRAF asume this relation ( <a href=\"https://iraf.readthedocs.io/en/latest/tasks/images/imfilter/rmode.html\">https://iraf.readthedocs.io/en/latest/tasks/images/imfilter/rmode.html</a> )\n",
    "</li>\n",
    "\n",
    "<li>As empirical mnemonic rule, in general <b>Mean, median and mode occur in the same order (or reverse order) as in the dictionary</b>, and the median is close to de mean than to the mode (as in the dictionary).</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21228a07-6ef1-4530-a546-bfb115b6b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangular PDF with mode =5 and mean = (a+b+mode)/3 = 10 \n",
    "a_tri=0.\n",
    "mode_tri = 5.\n",
    "b_tri = 25.\n",
    "x1a = np.array(triangularPDF(a_tri, mode_tri, b_tri, nMon=1000000))\n",
    "triangularMomentsAndQantiles(a_tri, mode_tri, b_tri,0.68)\n",
    "xMonSummaries_x1a = []\n",
    "xMonSummaries_x1a = plot_PDF(x1a,0.68,0.68)\n",
    "triangularPLOT(a_tri, mode_tri, b_tri,xsize=5,ysize= 3, title=\"x1 triangular PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec368a0b-ffc4-48f4-afb3-afe837083b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Slitp normal PDF with mode =10 and mean = (mode + sqrt(2/pi) * (sig_r - sig_l)) = 15\n",
    "mean_spn = 10.\n",
    "mode_spn = 15.\n",
    "sigl_spn = 7.\n",
    "sigr_spn = (mean_spn - mode_spn)*np.sqrt(math.pi/2.) + sigl_spn\n",
    "print(\"sigma_right =\",sigr_spn)\n",
    "x2a = np.array(splitnormalPDF(mode_spn,sigl_spn,sigr_spn,nMon=1000000))\n",
    "splitnormalMomentsAndQantiles(mode_spn,sigl_spn,sigr_spn,0.68)\n",
    "xMonSummaries_x2a = []\n",
    "xMonSummaries_x2a = plot_PDF(x2a,0.68,0.68,xsize=10,ysize= 5)\n",
    "splitnormalPLOT(mode_spn,sigl_spn,sigr_spn, xsize=5,ysize= 3, title=\"x2 splitNormal PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a44ea7-e091-4fcd-a56a-d5645549efb1",
   "metadata": {},
   "source": [
    "### Notes about dispresion measurements and probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afa516-4c6f-4d7f-a59f-632555a1f91d",
   "metadata": {},
   "source": [
    "Important enoguh:\n",
    "\n",
    "- (median, quatiles) and (mode, minimun-intervals) provide information about the probabilities (since require to define integral limits)\n",
    "- (mean, standard deviation) <b>DO NOT</b> povide information about probabilities (integral limits are always $-\\infty, + \\infty$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d1bd15-45dc-4772-ac4d-99d512a7b018",
   "metadata": {},
   "source": [
    "The mean and variance have very special properties: \n",
    "<ul>\n",
    "    <li><font color=\"green\">the mean (and the variance) of a sum is the sum of the means (and the variance) whatever de distribution.</font> It sound trivial but it requires some advanced statistics as characteristic functions and cumulants (more later)</li>\n",
    "    <li><font color=\"green\"> the variance it is the <i>lowest posible measure dispersion</i></font> (being dispersion the distance with respect a given point): the distance of all the points respect to a point $c$ is (note that $\\mu_2 = \\mu'_2 - {\\mu'}^2$)\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mu_2(c) &=& \\int (x -  c)^2\\, f(x)\\, \\mathrm{d}x \\nonumber \\\\\n",
    "&= & \\int (x^2 - 2\\, c\\,x + c^2)\\, f(x)\\, \\mathrm{d}x  \\nonumber \\\\\n",
    "&= & \\int (x^2 - {\\mu'}^2 + {\\mu'}^2 - 2\\, c\\,x + c^2)\\, f(x)\\, \\mathrm{d}x  \\nonumber \\\\\n",
    "&= & \\left(\\int (x^2 f(x)\\, \\mathrm{d}x \\right) - {\\mu'}^2  + ( {\\mu'}^2 - 2\\, c\\,\\mu' + c^2 ) \\\\\n",
    "&=&  \\mu_2  {\\color{red} + ( {\\mu'} - c)^2 }\n",
    "\\end{eqnarray}\n",
    "\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c3705-5e91-4460-a651-0e6a1c7de1cf",
   "metadata": {},
   "source": [
    "## 3. Uncertainty propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e3451f-010c-452e-8363-d61f1b7f2f2b",
   "metadata": {},
   "source": [
    "Lets check how uncertainty propagation works and what is porpagated. To do show, let us assume a very very simple case, the linear combination of two variables \n",
    "<br><br>\n",
    "<center>\n",
    "    $ w = 3 \\times x_1 + 2 \\times x_2$ \n",
    "</center>\n",
    "<br><br>\n",
    "wich, atendign to uncertainty propagation formulae, the previos formule shoud work for the assumed central value and the final uncertainty $\\delta_w$ should be obtained as:\n",
    "<br><br>\n",
    "<center>\n",
    "    $  \\delta_w^2 = 3 \\times \\delta_{x_1}^2 + 2 \\times \\delta_{x_2}^2 $ \n",
    "</center>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df840cd6-dba2-49df-85ba-579c9cf047fd",
   "metadata": {},
   "source": [
    "We also assume that  $x_1$ follows a triangularPDF and $x_2$ follows and split normal PDF with the following parameters:<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>$x_1$</td>\n",
    "        <td></td>\n",
    "        <td>$x_2$</td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Shape</td>\n",
    "        <td>triangular</td>\n",
    "        <td></td>\n",
    "        <td>Slipt Normal</td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>a=0, b=25, $\\hat{x}=5$</td>\n",
    "        <td>$\\sigma$ or $\\Delta/2$</td>\n",
    "        <td>$\\hat{x}=15$, $\\sigma_l =7$, $\\sigma_r=0.73$</td>\n",
    "        <td>$\\sigma$ or $\\Delta/2$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mean $\\mu$</td>\n",
    "        <td>10</td>\n",
    "        <td>5.4</td>\n",
    "        <td>10</td>\n",
    "        <td>4.40</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>median $\\bar{x}^{+(\\mathrm{84Q}-\\bar{x})}_{-(\\bar{x} - \\mathrm{16Q})}$<br><br>\n",
    "            <p style=\"font-size:8px\">$\\mathrm{16Q}, \\bar{x}, \\mathrm{84Q}$</p></td>\n",
    "        <td>$9.19_{-4.72}^{+6.86}$<br><br>\n",
    "            <p style=\"font-size:8px\">$4.47, 9.19, 16.06$</p></td>\n",
    "        <td>5.80</td>\n",
    "        <td>$10.84_{-5.30}^{+3.53}$<br><br>\n",
    "            <p style=\"font-size:8px\">$5.54, 10.84, 14.37$</p></td>\n",
    "        <td>4.42</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mode $\\hat{x}^{+(\\mathrm{upCL68}-\\bar{x})}_{-(\\bar{x} - \\mathrm{lowCL68})}$<br><br>\n",
    "            <p style=\"font-size:8px\">$\\mathrm{lowCL68}, \\hat{x}, \\mathrm{upCL68}$</p></td>\n",
    "        <td>$5_{-2.54}^{+8.80}$<br><br>\n",
    "            <p style=\"font-size:8px\">$2.46, 5., 13.80$</p></td>\n",
    "        <td>5.67</td>\n",
    "        <td>$15_{-7.62}^{+0.46}$<br><br>\n",
    "            <p style=\"font-size:8px\">$7.38, 15., 15.46$</p></td>\n",
    "        <td>4.04</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6557e63-03a7-4515-8036-e30793a0f30a",
   "metadata": {},
   "source": [
    "So we would expect (applying the $w$ formluae to reference values, 16Q, 84Q, lowCL68 y upCL68, and $\\delta_w$ to $\\sigma$ and $\\Delta/2$): \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td colspan = \"4\">$3 \\times x_1 2 \\times x_2$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Shape</td>\n",
    "        <td  colspan = \"4\">Unnkown (but see below)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>reference value</td>\n",
    "        <td>$\\sigma$ or $\\Delta/2$</td>\n",
    "        <td>Intervals<br>\n",
    "            (16Q,84Q, lowCL68, upCL68)</td>\n",
    "        <td>Intervals<br>\n",
    "            ref val(col2) $\\pm \\sigma$ or $\\Delta/2$ (col3)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mean $\\mu$</td>\n",
    "        <td>50</td>\n",
    "        <td>11.23</td>\n",
    "        <td></td>\n",
    "        <td>(38.77, 61.23)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>median</td>\n",
    "        <td>49.25</td>\n",
    "        <td>11.67</td>\n",
    "        <td>(24.49,76.92)</td>\n",
    "        <td>(37.58,60.92)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mode</td>\n",
    "        <td>45</td>\n",
    "        <td>11.36</td>\n",
    "        <td>(22.14,72.32)</td>\n",
    "        <td>(33.64,56.36)</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab707e0-ceca-4836-8b27-1852d5317ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1b = np.array(triangularPDF(a_tri, mode_tri, b_tri,nMon=1000000))\n",
    "xMonSummaries_x1b = []\n",
    "xMonSummaries_x1b = plot_PDF(x1b,0.68,0.68,xsize=7,ysize=4,title=\"x1b (Triangular)\")\n",
    "x1c = np.array(triangularPDF(a_tri, mode_tri, b_tri,nMon=1000000))\n",
    "xMonSummaries_x1c = []\n",
    "xMonSummaries_x1c = plot_PDF(x1c,0.68,0.68,xsize=7,ysize=4,title=\"x1c (Triangular)\")\n",
    "x2b = np.array(splitnormalPDF(mode_spn,sigl_spn,sigr_spn,nMon=1000000))\n",
    "xMonSummaries_x2b = []\n",
    "xMonSummaries_x2b = plot_PDF(x2b,0.68,0.68,xsize=7,ysize=4,title=\"x2b (splitNormal)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8951e-2958-4672-8bb7-09093a854f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array(empty(1000000))\n",
    "w = np.add(x1a,x1b)\n",
    "w = np.add(w,x1c)\n",
    "w = np.add(w,x2a)\n",
    "w = np.add(w,x2b)\n",
    "xMonSummaries_x2b = []\n",
    "xMonSummaries_x2b = plot_PDF(w, 0.68, 0.68,title=\"3 x1 + 2 x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cb712-cf8a-4e05-842b-a5025ff5f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a = powerlawMomentsAndQantiles(1,15,-2.35,0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b714b-21c9-4bca-b25f-8bcae729754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_1 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_2 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_3 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_4 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_5 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_6 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_7 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_8 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_9 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "x3_10 = np.array(powerlawPDF(1,15,-2.35,nMon=1000000))\n",
    "\n",
    "w2 = np.array(empty(1000000))\n",
    "w2 = np.add(x3_1,x3_2)\n",
    "w2 = np.add(w2,x3_3)\n",
    "w2 = np.add(w2,x3_4)\n",
    "w2 = np.add(w2,x3_5)\n",
    "w2 = np.add(w2,x3_6)\n",
    "w2 = np.add(w2,x3_7)\n",
    "w2 = np.add(w2,x3_8)\n",
    "w2 = np.add(w2,x3_9)\n",
    "w2 = np.add(w2,x3_10)\n",
    "xMonSummaries_w2 = []\n",
    "xMonSummaries_w2 = plot_PDF(w2, 0.68, 0.68,title=\"Power law Sum, original mean 2.42, median 1.64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc4b6f6-2f56-46ab-ac8c-45e24d54d420",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29307cec-6e73-433f-8a12-da269897c7c7",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td colspan = \"5\"><center>$w =3 \\times x_1  + 2 \\times x_2$</center></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Shape</td>\n",
    "        <td  colspan = \"5\">Gaussian-like (quite symetric!!)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td>reference value</td>\n",
    "        <td>$\\sigma$ or $\\Delta/2$</td>\n",
    "        <td>Intervals<br>\n",
    "            (16Q,84Q, lowCL68, upCL68)</td>\n",
    "        <td>Intervals<br>\n",
    "            ref val(col2) $\\pm \\sigma$ or $\\Delta/2$ (col3)</td>\n",
    "        <td><b>Result</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>&#128073; mean $\\mu$ &#129392;</td>\n",
    "        <td><font color=\"green\">50</font></td>\n",
    "        <td><font color=\"green\">11.23</font></td>\n",
    "        <td></td>\n",
    "        <td><font color=\"green\">(38.77, 61.23)</font></td>\n",
    "        <td><b>50.01 (38.77,61.25) $\\sigma = 11.24$</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>median &#129488;&#128530;</td>\n",
    "        <td><font color=\"red\">49.25</font></td>\n",
    "        <td><font color=\"red\">11.67</font></td>\n",
    "        <td><font color=\"red\">(24.49,76.92)</font></td>\n",
    "        <td><font color=\"red\">(37.58,60.92)</font></td>\n",
    "        <td><b>49.88 (38.82, 61.29) $\\Delta/2= 11.235$</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>mode &#129318;&#127996; &#128534;</td>\n",
    "        <td><font color=\"red\">45</font></td>\n",
    "        <td><font color=\"red\">11.36</font></td>\n",
    "        <td><font color=\"red\">(22.14, 72.32)</font></td>\n",
    "        <td><font color=\"red\">(33.64, 56.36)</font></td>\n",
    "        <td><b>49.17 (38.36, 61.77) $\\Delta/2= 11.705$</b></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12423be-d9fa-4d3c-80d7-7fe2b29282fe",
   "metadata": {},
   "source": [
    "Actually, all of this is quoted in the <a href=\"https://www.iso.org/sites/JCGM/GUM-introduction.htm\"><i>Guide to the expresion of uncertainty in measurements, GUM</i></a> (and in more stataisitical books), and all avanced probability theories works with means $\\mu$ and variuances $\\sigma^2$, there is a formal mathematical framework to do so!!, but... \n",
    "\n",
    "\n",
    "<blockquote>\"... There is, instead, no probability theory theorem\n",
    "which gives a simple propagation rule of mode, median and probability intervals... \" </blockquote>\n",
    "<div align=\"right\">D'Agostini (2013)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77afb07-f1d5-455e-a5f6-27171c78fa62",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Another more clear example (power laws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8415df-00c9-4cf3-bd45-5c82447ac8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdum = [] \n",
    "xdum = powerlawMomentsAndQantiles(1.,20.,-2.35,0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261d476-c732-4e1e-be09-39023c1e31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_1 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_2 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_3 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_4 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_5 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_6 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_7 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_8 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_9 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "x3_10 = np.array(powerlawPDF(1.,20.,-2.35))\n",
    "w2 = np.array(empty(1000000))\n",
    "w2 = np.add(x3_1,x3_2)\n",
    "w2 = np.add(w2,x3_3)\n",
    "w2 = np.add(w2,x3_4)\n",
    "w2 = np.add(w2,x3_5)\n",
    "w2 = np.add(w2,x3_6)\n",
    "w2 = np.add(w2,x3_7)\n",
    "w2 = np.add(w2,x3_8)\n",
    "w2 = np.add(w2,x3_9)\n",
    "w2 = np.add(w2,x3_10)\n",
    "\n",
    "print(f'Print Original Values (again):')\n",
    "xdum = powerlawMomentsAndQantiles(1.,20.,-2.35,0.68)\n",
    "print('  ')\n",
    "print(f\"   Exepected values: mean= {(xdum[0]*10.):.4f}, std= {(xdum[1]*np.sqrt(10.)):.4f}\")\n",
    "print('  ')\n",
    "xMonSummaries_x3b = []\n",
    "xMonSummaries_x3b = plot_PDF(w2, 0.68, 0.68,title=\"Power law x 10; Original: mean 2.55, Median 1.64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278db47-5ab5-4b08-81f2-8763ebb64914",
   "metadata": {},
   "source": [
    "## Take home points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e8dc9-7a20-47db-986f-292191a44a45",
   "metadata": {},
   "source": [
    "&#128073; You can use whatever you want to describe a PDF and uncertainties (If you are a gambler, mode and confidence interval is, some how, more realistic as summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384cbe08-38ed-429b-bebd-cc2fb490ed6e",
   "metadata": {},
   "source": [
    "&#128073; For histograms (and related integrals in probability!!) The meaning of limits must be <font color=\"green\">$a \\le x \\lt b$</font> or <font color=\"green\">$a \\lt x \\le b$</font> but never <font color=\"red\">$a \\le x \\le b$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204bfb9-b19f-4df6-b05c-da09a0f335a9",
   "metadata": {},
   "source": [
    "<br>\n",
    "If you want to provide values to be used later by others (or if you want to propagate uncertinties)\n",
    "<center>\n",
    "     &#128073; <font color=\"green\">provide ALWAYS <b>mean, $\\mu$</b> and <b>standard deviation, $\\sigma$</b> or <b>variance, $\\sigma^2$</b></font><br>\n",
    "since <font color=\"green\"><b>they are the only ones that works in uncertainty propagation formlae</b></font>!!\n",
    "</center>\n",
    "<br>\n",
    "and do not get confussed by the fact that median and mean values are close ech other!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e989c87d-0049-4207-868a-e50d5ca6d50e",
   "metadata": {},
   "source": [
    "&#128073; Standard devidation <font color=\"green\">DO NOT PROVIDE confidence interval</font> ($\\mu \\pm \\sigma$ makes no sense unless the PDF is gaussian, and it is not always the case!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697bbb0e-2a17-4318-a037-4b73fd0b5843",
   "metadata": {},
   "source": [
    "&#128073; Equaly, a probability inteval of 68% can be obtained in very difrent ways (about mean, median or mode). But acutally, the use of the magic number of 68% have to do gaussian you can use the value you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedabc12-abff-4f78-85df-2f7734ce2fe3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bonus track: Gaia, paralax, $\\left< 1/x \\right>$ and $\\sigma^2(1/x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfaa72-b0ba-4287-b51a-8fe9d6a504b9",
   "metadata": {},
   "source": [
    "From Cerviño &amp; Valls-Gabaud M.N.R.A.S. 2003, 338, 481 <a href=\"https://ui.adsabs.harvard.edu/abs/2003MNRAS.338..481C/abstract\">On biases in the predictions of stellar population synthesis models</a>, where it is studied the case of ratio distributions. Lets  $x_\\pi$ be the paralax, $\\mu_\\pi$ the mean value obtained from GAIA observations, and $\\sigma_\\pi$ the standard deviation of $\\mu_\\pi$ (which would vary when the number of observations incerases). The distance is then obtained as $d = 1/x_\\pi$. Making a Taylor expansion around $\\mu_\\pi$ \n",
    "<center>\n",
    "    \\begin{equation}\n",
    "          \\frac{1}{x_\\pi} = \\sum_{n \\ge 0} (-1)^n \\frac{1}{\\mu_\\pi} \\frac{(x_\\pi - \\mu_\\pi)^n}{\\mu_\\pi^n} = \\frac{1}{\\mu_\\pi}\\left(1 - \\frac{x_\\pi-\\mu_\\pi}{\\mu_\\pi}  + \\frac{(x_\\pi-\\mu_\\pi)^2}{\\mu_\\pi^2} - \\frac{(x_\\pi-\\mu_\\pi)^3}{\\mu_\\pi^3} + \\dots \\right)\n",
    "     \\end{equation}\n",
    "</center>\n",
    "\n",
    "then, we can obtain the mean and variance using the \"expectation value\" operator $\\mathrm{E}[f(x)] = \\int f(x)\\, \\varphi(x) \\mathrm{d}x$ and $\\mathrm{var}[f(x)] = \\mathrm{E}[f(x)^2] - \\mathrm{E}[f(x)]^2$:\n",
    "\n",
    "<center>\n",
    "    \\begin{eqnarray}\n",
    "        \\mu\\left(\\frac{1}{\\pi}\\right) & = & \\frac{1}{\\mu_\\pi} \\left( 1 + \\frac{\\sigma_\\pi^2}{\\mu_\\pi^2} \\color{grey}{-  \\frac{\\mu_{3}(\\pi)}{\\mu_\\pi^3}  + \\dots} \\right) \\\\\n",
    "        \\sigma^2 \\left(\\frac{1}{\\pi}\\right) & = & \\frac{\\sigma^2_\\pi}{\\mu_\\pi^4} \\left( 1 - \\frac{\\sigma_\\pi^2}{\\mu_\\pi^2}\\color{grey}{ - \\frac{2 \\mu_{3,\\pi}}{\\mu_\\pi \\sigma^2_\\pi} \\left(1- \\frac{\\sigma^2_\\pi}{\\mu_\\pi^2} + \\frac{\\mu_{3,\\pi}}{2\\,\\mu_\\pi^3} +  \\dots  \\right)} \\right)           \\\\\n",
    "        \\end{eqnarray}\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8652c387-02a8-4684-89dd-9472a23f616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nMon = 1000000\n",
    "d = np.array(empty(nMon))\n",
    "xPI = np.array(triangularPDF(1., 2.,3.,nMon=nMon))\n",
    "#xPI = np.array(splitnormalPDF(2., 0.5,0.3,nMon=nMon))\n",
    "print(\"Moments Original PDF x\")\n",
    "xmeanPi,xstdPi,xmodePi,xQ1Pi,xQ2Pi = triangularMomentsAndQantiles(1., 2.,3.,0.68)\n",
    "#xmeanPi,xstdPi,xmodePi,xQ1Pi,xQ2Pi = splitnormalMomentsAndQantiles(2., 0.5,0.3,0.68)\n",
    "print(\"\")\n",
    "print(\"Moments PDF (1/x)\")\n",
    "print(\"mean (1st order):\",1./xmeanPi,\"sigma (1st order):\",xstdPi/(xmeanPi*xmeanPi))\n",
    "print(\"mean (2nd order):\",(1./xmeanPi)*(1.+(xstdPi*xstdPi/(xmeanPi*xmeanPi))),\n",
    "      \"sigma (2nd order):\",(xstdPi/(xmeanPi*xmeanPi))*np.sqrt(1.-(xstdPi*xstdPi/(xmeanPi*xmeanPi))))\n",
    "print(\"\")\n",
    "d=1/xPI\n",
    "plot_PDF(d, 0.68, 0.68,ylog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6534cf-a87e-4612-8302-2127878623bb",
   "metadata": {},
   "source": [
    "This is the reason that GAIA distances would vary with the relase: the distance estimate depends on the uncertainty in the estimate of the paralax.. It is supposed that such uncertainty in the estimate will converge towards an estable value (and hence, the estimate of the distance)\n",
    "\n",
    "Also note that the variance in the distance is not so easily reproduced analyticaly ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb16d4bb-4922-4860-8d30-0f98228cfddd",
   "metadata": {},
   "source": [
    "## Fruther read:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec39e62-c58f-47ed-b1f4-c4a7e117b467",
   "metadata": {},
   "source": [
    "<font size=\"-1\">\n",
    "<ul>\n",
    "    <ol>\n",
    "        <li>Representation\n",
    "            <ul>\n",
    "                <li>Kendall's Advanced Theory of Statistics (Vol 1 Cap.1)</li>\n",
    "                <li>Maíz-Apellániz &amp Úbeda Ap.J. 2005, 629, 873, <a href=\"https://ui.adsabs.harvard.edu/abs/2005ApJ...629..873M/abstract\"><i>Numerical Biases on Initial Mass Function Determinations Created by Binning</i></a></li>\n",
    "                <li>Cerviño et al. 2013, A&amp;A 553, A31,  <a href=\"https://ui.adsabs.harvard.edu/abs/2013A%26A...553A..31C/abstract\"><i>Crucial aspects of the initial mass function. I. The statistical correlation between the total mass of an ensemble of stars and its most massive star</i></a></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Measurement of location and dispersion\n",
    "            <ul>\n",
    "                <li>Kendall's Advanced Theory of Statistics (Vol 1 Cap.2)</li>\n",
    "                <li><font color=\"green\" >&#128073; </font>D'Agostini & Raso (2000) <a href=\"http://arxiv.org/abs/hep-ex/0002056v1\">Uncertainties due to imperfect knowledge of systematic effects</a> Asimetric uncertinties</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Uncertainty propagation\n",
    "            <ul>\n",
    "                <li><a href=\"https://www.iso.org/sites/JCGM/GUM-introduction.htm\"><i>Guide to the expresion of uncertainty in measurements, GUM</i></a> (form the International Standarization Organization, ISO)<br>\n",
    "            In particular <a href=\"https://www.iso.org/sites/JCGM/GUM/JCGM100/C045315e-html/C045315e.html?csnumber=50461\">Sect 7: Reporting uncertainty</a></li>\n",
    "                <li>D'Agostini (2013) <i>Bayesian reasoning in data analisys . A critical introduction</i> World Scientific Publishing 2003 (<a href=\"https://www.roma1.infn.it/~dagos/WSPC/index.html\">Table of contents</a>)</li>\n",
    "                <li>Cerviño &amp; Valls-Gabaud M.N.R.A.S. 2003, 338, 481 <a href=\"https://ui.adsabs.harvard.edu/abs/2003MNRAS.338..481C/abstract\">On biases in the predictions of stellar population synthesis models</a></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>Moments, cumulants and PDF description from them (IMF, integrated luminosity, the dependence with numer of stars, and so on)\n",
    "            <ul>\n",
    "              <li>Kendall's Advanced Theory of Statistics (Vol 1 Cap.4)</li>\n",
    "                <li>Cerviño &map; Luiridiana 2006, A&amp;A 451, 475 <a href=\"https://ui.adsabs.harvard.edu/abs/2006A%26A...451..475C/abstract\">Confidence limits of evolutionary synthesis models. IV. Moving forward to a probabilistic formulation</a></li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ol>\n",
    "</ul>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
